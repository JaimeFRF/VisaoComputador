{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Image Enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy\n",
      "  Downloading scipy-1.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in ./.venv/lib/python3.12/site-packages (from scipy) (2.2.3)\n",
      "Downloading scipy-1.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: scipy\n",
      "Successfully installed scipy-1.15.2\n"
     ]
    }
   ],
   "source": [
    "! pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Path to directory with images\n",
    "dataDir = 'images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open noisy image\n",
    "img = cv2.imread(os.path.join(dataDir, 'zebra_01_noisy.jpg'))\n",
    "\n",
    "# Show image\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Filtering and Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Check tutorial here!](https://docs.opencv.org/4.x/dc/dd3/tutorial_gausian_median_blur_bilateral_filter.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply mean filter to the image\n",
    "img_mean_filter = cv2.blur(img, (4,4))\n",
    "\n",
    "# Show image\n",
    "cv2.imshow('image', img_mean_filter)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1.1: Apply median, Gaussian and bilateral filters to the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_filter_img = cv2.medianBlur(img, 5)\n",
    "gaussian_filter_img = cv2.GaussianBlur(img, (5, 5), 0, 0)\n",
    "bilateral_filter_img = cv2.bilateralFilter(img, 15, 75, 75)\n",
    "\n",
    "cv2.imshow(\"image\", img)\n",
    "cv2.imshow(\"Median Filter\", median_filter_img)\n",
    "cv2.imshow(\"Gaussian Filter\", gaussian_filter_img)\n",
    "cv2.imshow(\"Bilateral Filter\", bilateral_filter_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1.2: Add salt and pepper noise to an image and check which filter works best at removing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def add_noise(img): \n",
    "    row , col, _  = img.shape \n",
    "\n",
    "    number_of_pixels = random.randint(300, 10000) \n",
    "    for _ in range(number_of_pixels): \n",
    "        y_coord=random.randint(0, row - 1) \n",
    "        x_coord=random.randint(0, col - 1) \n",
    "        img[y_coord][x_coord] = 255\n",
    "\n",
    "    number_of_pixels = random.randint(300 , 10000)\n",
    "    for _ in range(number_of_pixels): \n",
    "        y_coord=random.randint(0, row - 1) \n",
    "        x_coord=random.randint(0, col - 1) \n",
    "        img[y_coord][x_coord] = 0\n",
    "    return img \n",
    "\n",
    "\n",
    "noisy_img = add_noise(img) \n",
    "\n",
    "median_filter_img = cv2.medianBlur(noisy_img, 5)\n",
    "gaussian_filter_img = cv2.GaussianBlur(noisy_img, (5, 5), 0, 0)\n",
    "bilateral_filter_img = cv2.bilateralFilter(noisy_img, 15, 75, 75)\n",
    "\n",
    "\n",
    "cv2.imshow(\"Noisy Image\", noisy_img)\n",
    "cv2.imshow(\"Median Filter\", median_filter_img)\n",
    "cv2.imshow(\"Gaussian Filter\", gaussian_filter_img)\n",
    "cv2.imshow(\"Bilateral Filter\", bilateral_filter_img)\n",
    "\n",
    "while True:\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Why did the bilateral filter work well previously, but not now?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1.3: Apply your own 3x3 mean filter using [ndimage.convolve()](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.convolve.html). Look at the lecture slides for the filter definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "img = cv2.imread(os.path.join(dataDir, 'home.jpg'), cv2.IMREAD_GRAYSCALE)\n",
    "k = np.ones((3,3))\n",
    "k /= np.sum(k)\n",
    "\n",
    "# k = np.array([[0,-1,0], [-1,4,-1], [0,-1,0]], float)\n",
    "\n",
    "new_img = ndimage.convolve(img / 255, k)\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.imshow(\"New image\", new_img)\n",
    "\n",
    "\n",
    "while True:\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1.4: Apply your own 3x3 Gaussian filter using [ndimage.convolve()](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.convolve.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "img = cv2.imread(os.path.join(dataDir, 'zebra_01_noisy.jpg'), cv2.IMREAD_GRAYSCALE)\n",
    "k = np.array([[1, 2, 1], [2, 4, 2], [1, 2, 1]], float)\n",
    "k /= np.sum(k)\n",
    "\n",
    "new_img = ndimage.convolve(img / 255, k)\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.imshow(\"New Image\", new_img)\n",
    "\n",
    "while True:\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1.5: Apply two 3x3 Sobel filters (one in the X-direction, the other in the Y-direction) using [ndimage.convolve()](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.convolve.html). Look at the lecture slides for the filter definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Not sure about this one\n",
    "\n",
    "from scipy import ndimage\n",
    "img = cv2.imread(os.path.join(dataDir, 'apple.jpg'), cv2.IMREAD_GRAYSCALE)\n",
    "k_x = np.array([[-1, 0, 1], [-2, 0, 2], [1, 0, 1]], float)\n",
    "k_y = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]], float)\n",
    "\n",
    "\n",
    "new_img_x = ndimage.convolve(img / 255, k_x)\n",
    "new_img_y = ndimage.convolve(img / 255, k_y)\n",
    "\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.imshow(\"New Image X filter\", new_img_x)\n",
    "cv2.imshow(\"New Image Y filter\", new_img_y)\n",
    "\n",
    "while True:\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1.6: Apply your own 3x3 Gaussian filter using [ndimage.convolve()](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.convolve.html), but now to a colored image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "img = cv2.imread(os.path.join(dataDir, 'apple.jpg'))\n",
    "\n",
    "k = np.array([[1, 2, 1], [2, 4, 2], [1, 2, 1]], float)\n",
    "k /= np.sum(k)\n",
    "\n",
    "# We apply convolution to each channel and then stack the filtered channels back into an image\n",
    "new_img = np.dstack([ndimage.convolve(img[:, :, c] / 255, k) for c in range(img.shape[2])])\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.imshow(\"New Image\", new_img)\n",
    "\n",
    "while True:\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Histogram Equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load low contrast image\n",
    "img = cv2.imread(os.path.join(dataDir, 'face_lowContrast_01.jpg'), 0) # Change this, according to your image's path\n",
    "\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Histograms Equalization](https://docs.opencv.org/master/d6/dc7/group__imgproc__hist.html#ga7e54091f0c937d49bf84152a16f76d6e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increasing contrast with Histograms Equalization\n",
    "img_with_he = cv2.equalizeHist(img)\n",
    "\n",
    "cv2.imshow('histogram_equalization', img_with_he)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Contrast Limited Adaptive Histogram Equalization](https://docs.opencv.org/master/d6/dc7/group__imgproc__hist.html#gad689d2607b7b3889453804f414ab1018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increasing contrast with CLAHE\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "img_with_CLAHE = clahe.apply(img)\n",
    "\n",
    "cv2.imshow('clahe', img_with_CLAHE)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2.1: Apply Histogram Equalization to a colored image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(os.path.join(dataDir, 'fruits.jpg'))\n",
    "img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "\n",
    "# equalize the histogram of the Y channel\n",
    "img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])\n",
    "# convert the YUV image back to RGB format\n",
    "img_output = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)\n",
    "\n",
    "cv2.imshow('Color input image', img)\n",
    "cv2.imshow('Histogram equalized', img_output)\n",
    "\n",
    "while True:\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2.2: Apply CLAHE to a colored image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(os.path.join(dataDir, 'fruits.jpg'))\n",
    "\n",
    "\n",
    "new_img = cv2.cvtColor(img, cv2.COLOR_BGR2Lab)\n",
    "clahe = cv2.createCLAHE(clipLimit=10, tileGridSize=(8, 8))\n",
    "new_img[:, :, 0] = clahe.apply(new_img[:, :, 0])\n",
    "new_img = cv2.cvtColor(new_img, cv2.COLOR_Lab2BGR)\n",
    "\n",
    "# Display images\n",
    "cv2.imshow('Color input image', img)\n",
    "cv2.imshow('Histogram equalized', new_img)\n",
    "\n",
    "while True:\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
