{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Edge and line detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in ./.venv/lib/python3.12/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in ./.venv/lib/python3.12/site-packages (from opencv-python) (2.2.3)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.12/site-packages (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in ./.venv/lib/python3.12/site-packages (from matplotlib) (2.2.3)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.12/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install opencv-python\n",
    "! pip install numpy\n",
    "! pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "dataDir = 'images' # Change this, according to your images' directory path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open image\n",
    "img = cv2.imread(os.path.join(dataDir, 'corridor_01.jpg')) # Change this, according to your image's path\n",
    "\n",
    "# Convert to grayscale\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Sobel Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detecting edges using the [Sobel Filter](https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gacea54f142e81b6758cb6f375ce782c8d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the first derivatives of the image in x and y\n",
    "sobel_x = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=5)\n",
    "sobel_y = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=5)\n",
    "\n",
    "# Show the images\n",
    "cv2.imshow(\"Sobel X\", sobel_x)\n",
    "cv2.imshow(\"Sobel Y\", sobel_y)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1.1: Calculate the gradient by combining the X and Y axes and show the gradient image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = np.sqrt(sobel_x ** 2 + sobel_y ** 2)\n",
    "grad_norm = (grad * 255 / grad.max()).astype(np.uint8)\n",
    "                                            \n",
    "cv2.imshow(\"Image\", grad_norm)\n",
    "while True:\n",
    "    if cv2.waitKey(1) == ord(\"q\"):\n",
    "        break\n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1.2: Threshold the gradient image using a [trackbar](https://docs.opencv.org/4.x/da/d6a/tutorial_trackbar.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_threshold(value):\n",
    "    _, thresh_img = cv2.threshold(grad_norm, value, 255, cv2.THRESH_BINARY)\n",
    "    cv2.imshow(\"image\", thresh_img)    \n",
    "\n",
    "cv2.namedWindow(\"image\")\n",
    "cv2.createTrackbar(\"T\", \"image\", 0, 255, update_threshold)\n",
    "\n",
    "update_threshold(0)\n",
    "while True:\n",
    "    if cv2.waitKey(1) == ord(\"q\"):\n",
    "        break\n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1.3: Test the effect of applying Gaussian blur filters of different sizes before applying Sobel filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian = cv2.GaussianBlur(img, (5, 5), 0, 0)\n",
    "gaussian_2 = cv2.GaussianBlur(img, (11, 11), 0, 0)\n",
    "gaussian_3 = cv2.GaussianBlur(img, (25, 25), 0, 0)\n",
    "gaussian_4 = cv2.GaussianBlur(img, (49, 49), 0, 0)\n",
    "\n",
    "\n",
    "def compute_sobel(image):\n",
    "    sobel_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=5)\n",
    "    sobel_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=5)\n",
    "    grad = np.sqrt(sobel_x ** 2 + sobel_y ** 2)\n",
    "    grad_norm = (grad * 255 / grad.max()).astype(np.uint8)\n",
    "    return grad_norm\n",
    "\n",
    "res1 = compute_sobel(gaussian)\n",
    "res2 = compute_sobel(gaussian_2)\n",
    "res3 = compute_sobel(gaussian_3)\n",
    "res4 = compute_sobel(gaussian_4)\n",
    "\n",
    "cv2.imshow(\"Image 1\", res1)\n",
    "cv2.imshow(\"Image 2\", res2)\n",
    "cv2.imshow(\"Image 3\", res3)\n",
    "cv2.imshow(\"Image 4\", res4)\n",
    "\n",
    "while True:\n",
    "    if cv2.waitKey(1) == ord(\"q\"):\n",
    "        break\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1.4: Experiment with different kernel sizes in the sobel filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sobel(image, kernel):\n",
    "    sobel_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=kernel)\n",
    "    sobel_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=kernel)\n",
    "    grad = np.sqrt(sobel_x ** 2 + sobel_y ** 2)\n",
    "    grad_norm = (grad * 255 / grad.max()).astype(np.uint8)\n",
    "    return grad_norm\n",
    "\n",
    "\n",
    "res1 = compute_sobel(img, 5)\n",
    "res1 = compute_sobel(img, 15)\n",
    "res1 = compute_sobel(img, 25)\n",
    "res1 = compute_sobel(img, 31)\n",
    "\n",
    "cv2.imshow(\"Image 1\", res1)\n",
    "cv2.imshow(\"Image 2\", res2)\n",
    "cv2.imshow(\"Image 3\", res3)\n",
    "cv2.imshow(\"Image 4\", res4)\n",
    "\n",
    "while True:\n",
    "    if cv2.waitKey(1) == ord(\"q\"):\n",
    "        break\n",
    "cv2.destroyAllWindows() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Laplacian of Gaussians (LoG) and Difference of Gaussians (DoG)\n",
    "\n",
    "Edge detection using Laplacian of Gaussians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open image\n",
    "img = cv2.imread(os.path.join(dataDir, 'corridor_01.jpg')) # Change this, according to your image's path\n",
    "\n",
    "# Convert to grayscale\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Laplacian\n",
    "laplacian = cv2.Laplacian(img, cv2.CV_64F, ksize=3)\n",
    "\n",
    "cv2.imshow(\"LoG\", laplacian)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2.1: Verify the effects of using Gaussian Blur before applying the laplacian filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian = cv2.GaussianBlur(img, (15, 15), 0, 0)\n",
    "gaussian_laplacian = cv2.Laplacian(gaussian, cv2.CV_64F, ksize=3)\n",
    "\n",
    "cv2.imshow(\"LoG\", laplacian)\n",
    "cv2.imshow(\"LoG Gaussian\", gaussian_laplacian)\n",
    "\n",
    "while True:\n",
    "    if cv2.waitKey(1) == ord(\"q\"):\n",
    "        break\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2.2: Implement edge detection through Difference of Gaussians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_gaussian = cv2.GaussianBlur(img, (0, 0), 1.0)\n",
    "high_gaussian = cv2.GaussianBlur(img, (0, 0), 2.0)\n",
    "\n",
    "dog = low_gaussian - high_gaussian\n",
    "#dog = cv2.normalize(dog, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "\n",
    "cv2.imshow(\"Original\", img)\n",
    "cv2.imshow(\"DoG Edge Detection\", dog)\n",
    "while True:\n",
    "    if cv2.waitKey(1) == ord(\"q\"):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Canny Edge Filter\n",
    "\n",
    "Detect edges using the [Canny Filter](https://docs.opencv.org/master/dd/d1a/group__imgproc__feature.html#ga04723e007ed888ddf11d9ba04e2232de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a Canny Filter\n",
    "img_canny = cv2.Canny(img, 100, 200)\n",
    "\n",
    "cv2.imshow(\"Image\", img_canny)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 3.1: Implement two track bars to alter the low and high threshold values of the Canny filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow(\"Canny Edge Detection\")\n",
    "\n",
    "low_threshold = 50\n",
    "high_threshold = 150\n",
    "\n",
    "def update_low_threshold(val):\n",
    "    global low_threshold\n",
    "    low_threshold = val\n",
    "    apply_canny()\n",
    "\n",
    "def update_high_threshold(val):\n",
    "    global high_threshold\n",
    "    high_threshold = val\n",
    "    apply_canny()\n",
    "\n",
    "def apply_canny():\n",
    "    edges = cv2.Canny(img, low_threshold, high_threshold)\n",
    "    cv2.imshow(\"Canny Edge Detection\", edges)\n",
    "\n",
    "cv2.createTrackbar(\"Low Threshold\", \"Canny Edge Detection\", low_threshold, 255, update_low_threshold)\n",
    "cv2.createTrackbar(\"High Threshold\", \"Canny Edge Detection\", high_threshold, 255, update_high_threshold)\n",
    "\n",
    "apply_canny()\n",
    "\n",
    "while True:\n",
    "    if cv2.waitKey(1) == ord(\"q\"):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 3.2: Compare the results of applying the following two filters to the same image:\n",
    " - Sobel filter, with threshold t, after smoothing the image with a Gaussian blur filter with size s;\n",
    " - Canny filter, with \"low threshold\" = \"high threshold\" = t and \"aperture\" = s, using the same t and s values. Try also with a \"low threshold\" different from the \"high threshold\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 100\n",
    "s = (5,5)\n",
    "gaussian = cv2.GaussianBlur(img, s, 1.0)\n",
    "\n",
    "## DOUBS ABUT THI SONE ASK TEACHER\n",
    "\n",
    "sobel_x = cv2.Sobel(gaussian, cv2.CV_64F, 1, 0, ksize=5)\n",
    "sobel_y = cv2.Sobel(gaussian, cv2.CV_64F, 0, 1, ksize=5)\n",
    "grad = np.sqrt(sobel_x ** 2 + sobel_y ** 2)\n",
    "grad_norm = (grad * 255 / grad.max()).astype(np.uint8)\n",
    "\n",
    "_, img_one = cv2.threshold(grad_norm, t, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "#######################################################################\n",
    "\n",
    "img_two = cv2.Canny(img, t, t, apertureSize=s[0])\n",
    "img_three = cv2.Canny(img, t, t+50, apertureSize=s[0])\n",
    "\n",
    "cv2.imshow(\"First\", img_one)\n",
    "cv2.imshow(\"Second\", img_two)\n",
    "cv2.imshow(\"Third\", img_three)\n",
    "\n",
    "while True:\n",
    "    if cv2.waitKey(1) == ord(\"q\"):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra: Hough Line Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of [Standard Hough Lines Transform](https://docs.opencv.org/3.4/dd/d1a/group__imgproc__feature.html#ga46b4e588934f6c8dfd509cc6e0e4545a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening an image\n",
    "img2 = cv2.imread(os.path.join(dataDir, 'chessboard_02.jpg'))\n",
    "\n",
    "# Convert to grayscale\n",
    "img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Display image\n",
    "cv2.imshow(\"Image\", img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Detect the edges of the input image using a Canny Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Canny filter\n",
    "img2_canny = cv2.Canny(img2, 50, 200)\n",
    "\n",
    "# Create BGR copy of image\n",
    "img2_copy = cv2.cvtColor(img2_canny, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "# Display image\n",
    "cv2.imshow(\"Canny\", img2_canny)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Apply Hough Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_votes = 60\n",
    "\n",
    "lines = cv2.HoughLines(img2_canny, 1, np.pi / 180, num_votes, None, 0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Draw the lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "if lines is not None:\n",
    "    for i in range(0, len(lines)):\n",
    "        rho = lines[i][0][0]\n",
    "        theta = lines[i][0][1]\n",
    "        a = math.cos(theta)\n",
    "        b = math.sin(theta)\n",
    "        x0 = a * rho\n",
    "        y0 = b * rho\n",
    "        pt1 = (int(x0 + 1000*(-b)), int(y0 + 1000*(a)))\n",
    "        pt2 = (int(x0 - 1000*(-b)), int(y0 - 1000*(a)))\n",
    "        # Draw the line\n",
    "        cv2.line(img2_copy, pt1, pt2, (255,0,0), 3)\n",
    "\n",
    "cv2.imshow(\"Canny\", img2_canny)\n",
    "cv2.imshow(\"Image\", img2_copy)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
